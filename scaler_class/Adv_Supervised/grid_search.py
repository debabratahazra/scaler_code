#import random forest
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
import numpy as np
np.random.seed(0)

X_train = [[-1.3866988473336963, -1.4659283769652018, 0.21908962542114993, -0.5705832721154885, -0.39026284294183144], [-0.7420732896222481, -0.08018384934842993, 3.289428542039212, -0.2964031797183057, -1.125040628296576], [0.21851716927727832, 1.0189924747916534, -0.7926306280393199, -0.2962365155662698, 0.9186990330562381], [0.3301766397890254, -0.16234277642612435, 0.7791050210600118, -0.2789394183794175, -0.35256672506010045], [-0.5564673667894178, 0.5994216521345357, 0.40496709263900627, 0.13789108254811427, -1.6797693374581222], [-0.4720940445492414, 0.7586066378374584, 0.11238256186733482, -0.04938846752263362, 0.9002597707743003], [0.6349076398170301, 0.1836763524015007, 1.1110767907487034, 0.45180245509492484, -0.4783224076406436], [-1.283707351437791, 0.6660298150052364, 1.5696565285122108, -0.6888351361949948, -0.8067418148384723], [1.4486773262255297, 1.1533634571229343, 0.25142391222574634, 0.2030471272777417, -0.9163693858589892], [0.2348414093321201, -0.9172108964271672, 0.9729754272245916, 1.3780385868308136, -0.09055892098596163], [0.6354361842373741, -0.8190222254833313, -0.00038109394560143146, -0.4358096089529283, -1.0552640440044254], [0.39286286277430754, 1.1227932444987576, -0.4560006105768751, 1.540942085589407, 0.8198553203534422], [-0.015930330301621193, 0.1549232280701, -1.4180291585154143, -2.1379838467838814, 1.220286714782214], [-0.19670287799839387, -0.49256946476607977, 0.3263897035897652, 0.742732407535864, 1.0944787425334823], [-0.2585046029453902, 0.15014998302969798, -0.45023021276200786, 0.4195424096764816, 1.0271758933897448]]
Y_train = [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1]
X_valid = [[-1.0242005313937477, 0.976281826209692, -0.08920283415553125, 1.3788073908145468, -1.910582206697658], [-0.5261119238131993, -0.3443793123408228, -0.27647010369805974, -0.922859596433698, 1.1023500179176688], [-1.3564905359324015, -0.8475433541986344, 0.18234188313329097, -0.6098825928188724, 1.16813242929799], [1.5023509595263478, 0.25117399808101465, 1.4985390708977253, -1.0426432774270358, 1.3538360431859358], [-2.124074148585913, 1.9821906863146135, 1.2206529386813578, -0.5057455727664389, -0.9943646677180753], [0.008449083666056009, -0.916539897668125, -1.4137008074570467, 1.6437768066205727, 1.0730437206988162], [0.692291104684553, 0.8290740382224973, -0.8614162963750803, -0.5663186573498192, 0.9446455766399413], [1.1510791022492721, -1.2216360043806689, -1.6227635183877651, -1.9345051157994586, -0.5498461748799024], [-0.7861882343032912, 0.8254785094597348, 0.06800567662367255, -0.7727384191587424, 0.87627995234417], [0.4207745468774598, -0.8274281056562529, -0.03974762336921463, -0.0005562277737053338, 0.8612479876410026]]
Y_valid = [0, 1, 1, 1, 0, 1, 1, 0, 1, 1]

n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 2)]
max_depth = [int(x) for x in np.linspace(10, 110, num = 2)]

#initialize the max_accuracy 
max_accuracy = 0.0

#2d list
hyperparameters = []    
#add all the possible combinations of the hyperparameters, each combination as a list
#YOUR CODE GOES HERE

for n_est in n_estimators:
    for m_depth in max_depth:
        hyperparameters.append([n_est, m_depth])
        
#YOUR CODE ENDS HERE

#iterate through all the possible combinations
for k in range(len(hyperparameters)):

    #equate the hyperparameters
    model = RandomForestClassifier(n_estimators=hyperparameters[k][0], max_depth=hyperparameters[k][1], random_state=42)
  
    model.fit( X_train, Y_train )
    
    # Prediction on validation set
    Y_pred = model.predict( X_valid )
    #calculate the accuracy of y_pred
    curr_accuracy = accuracy_score(Y_valid, Y_pred)
    
    #update the max_accuracy
    if max_accuracy < curr_accuracy :
        print("New max accuracy: ", curr_accuracy)          
        max_accuracy = curr_accuracy

print("Final Max Accuracy: ", np.round(max_accuracy, 2))